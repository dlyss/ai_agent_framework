# AI Agent Framework

ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„ AI Agent å¼€å‘æ¡†æ¶ï¼ŒåŸºäº **LangChain 1.x + FastAPI + Python**ï¼Œæ”¯æŒå¤šæ¨¡å‹è°ƒç”¨ã€RAGæ£€ç´¢å¢å¼ºã€æç¤ºè¯è·¯ç”±ã€è®°å¿†ç®¡ç†å’Œæ¨¡å‹å¾®è°ƒã€‚

## âœ¨ ç‰¹æ€§

- ğŸ¤– **å¤šæ¨¡å‹æ”¯æŒ**: OpenAI (GPT-3.5/4), é€šä¹‰åƒé—® (Qwen), LLaMA
- ğŸ“š **RAGç³»ç»Ÿ**: åŸºäº Milvus å‘é‡æ•°æ®åº“çš„æ£€ç´¢å¢å¼ºç”Ÿæˆ
- ğŸ§  **è®°å¿†ç®¡ç†**: çŸ­æœŸè®°å¿† + é•¿æœŸå‘é‡åŒ–è®°å¿†
- ğŸ¯ **æç¤ºè¯è·¯ç”±**: æ”¯æŒå…³é”®è¯ã€æ­£åˆ™ã€LLMæ™ºèƒ½è·¯ç”±
- ğŸ”§ **æ¨¡å‹å¾®è°ƒ**: æ”¯æŒå…¨é‡å¾®è°ƒå’Œ LoRA é«˜æ•ˆå¾®è°ƒ
- ğŸ” **JWTè®¤è¯**: å®Œæ•´çš„ç”¨æˆ·è®¤è¯ç³»ç»Ÿ
- ğŸŒŠ **WebSocket**: æµå¼è¾“å‡ºæ”¯æŒ

## ğŸ“ é¡¹ç›®ç»“æ„

```
ai_agent_framework/
â”œâ”€â”€ app/                        # FastAPI åº”ç”¨
â”‚   â”œâ”€â”€ main.py                # åº”ç”¨å…¥å£
â”‚   â”œâ”€â”€ config.py              # é…ç½®ç®¡ç†
â”‚   â””â”€â”€ api/
â”‚       â”œâ”€â”€ auth.py            # JWTè®¤è¯
â”‚       â”œâ”€â”€ deps.py            # ä¾èµ–æ³¨å…¥
â”‚       â””â”€â”€ routes/            # APIè·¯ç”±
â”‚           â”œâ”€â”€ auth.py        # è®¤è¯æ¥å£
â”‚           â”œâ”€â”€ chat.py        # å¯¹è¯æ¥å£
â”‚           â”œâ”€â”€ rag.py         # RAGæ¥å£
â”‚           â”œâ”€â”€ memory.py      # è®°å¿†æ¥å£
â”‚           â”œâ”€â”€ finetune.py    # å¾®è°ƒæ¥å£
â”‚           â””â”€â”€ websocket.py   # WebSocketæ¥å£
â”œâ”€â”€ core/                       # æ ¸å¿ƒæ¨¡å—
â”‚   â”œâ”€â”€ llm/                   # LLMå¤šæ¨¡å‹æ”¯æŒ
â”‚   â”‚   â”œâ”€â”€ base.py           # åŸºç±»
â”‚   â”‚   â”œâ”€â”€ openai_llm.py     # OpenAI
â”‚   â”‚   â”œâ”€â”€ qwen_llm.py       # é€šä¹‰åƒé—®
â”‚   â”‚   â”œâ”€â”€ llama_llm.py      # LLaMA
â”‚   â”‚   â””â”€â”€ factory.py        # å·¥å‚æ¨¡å¼
â”‚   â”œâ”€â”€ vector_store/          # å‘é‡æ•°æ®åº“
â”‚   â”‚   â”œâ”€â”€ base.py           # åŸºç±»
â”‚   â”‚   â””â”€â”€ milvus_store.py   # Milvuså®ç°
â”‚   â”œâ”€â”€ rag/                   # RAGæ¨¡å—
â”‚   â”‚   â”œâ”€â”€ embeddings.py     # å‘é‡åµŒå…¥
â”‚   â”‚   â”œâ”€â”€ retriever.py      # æ£€ç´¢å™¨
â”‚   â”‚   â””â”€â”€ chain.py          # RAGé“¾
â”‚   â”œâ”€â”€ prompt/                # æç¤ºè¯ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ manager.py        # æ¨¡æ¿ç®¡ç†
â”‚   â”‚   â””â”€â”€ router.py         # è·¯ç”±å™¨
â”‚   â”œâ”€â”€ memory/                # è®°å¿†æ¨¡å—
â”‚   â”‚   â”œâ”€â”€ base.py           # åŸºç±»
â”‚   â”‚   â”œâ”€â”€ short_term.py     # çŸ­æœŸè®°å¿†
â”‚   â”‚   â”œâ”€â”€ long_term.py      # é•¿æœŸè®°å¿†
â”‚   â”‚   â””â”€â”€ manager.py        # è®°å¿†ç®¡ç†å™¨
â”‚   â””â”€â”€ finetune/              # å¾®è°ƒæ¨¡å—
â”‚       â”œâ”€â”€ data_processor.py # æ•°æ®å¤„ç†
â”‚       â”œâ”€â”€ trainer.py        # è®­ç»ƒå™¨
â”‚       â””â”€â”€ lora_adapter.py   # LoRAé€‚é…å™¨
â”œâ”€â”€ schemas/                    # Pydanticæ¨¡å‹
â”œâ”€â”€ utils/                      # å·¥å…·æ¨¡å—
â”œâ”€â”€ .env.example               # ç¯å¢ƒå˜é‡ç¤ºä¾‹
â”œâ”€â”€ requirements.txt           # ä¾èµ–
â””â”€â”€ README.md
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

```bash
# å…‹éš†é¡¹ç›®
cd ai_agent_framework

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python -m venv venv
source venv/bin/activate  # Linux/Mac
# venv\Scripts\activate   # Windows

# å®‰è£…ä¾èµ–
pip install -r requirements.txt
```

### 2. é…ç½®ç¯å¢ƒå˜é‡

```bash
# å¤åˆ¶é…ç½®æ–‡ä»¶
cp .env.example .env

# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œé…ç½®ä»¥ä¸‹å¿…è¦é¡¹ï¼š
# - OPENAI_API_KEY (å¦‚æœä½¿ç”¨OpenAI)
# - DASHSCOPE_API_KEY (å¦‚æœä½¿ç”¨é€šä¹‰åƒé—®)
# - JWT_SECRET_KEY (ç”Ÿäº§ç¯å¢ƒåŠ¡å¿…ä¿®æ”¹)
```

### 3. å¯åŠ¨ Milvus (Docker)

```bash
# ä¸‹è½½ docker-compose æ–‡ä»¶
wget https://github.com/milvus-io/milvus/releases/download/v2.3.6/milvus-standalone-docker-compose.yml -O docker-compose.yml

# å¯åŠ¨ Milvus
docker-compose up -d
```

### 4. å¯åŠ¨æœåŠ¡

```bash
# å¼€å‘æ¨¡å¼
python -m app.main

# æˆ–ä½¿ç”¨ uvicorn
uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

è®¿é—® http://localhost:8000/docs æŸ¥çœ‹ API æ–‡æ¡£ã€‚

## ğŸ“– API ä½¿ç”¨ç¤ºä¾‹

### è®¤è¯

```python
import httpx

# æ³¨å†Œç”¨æˆ·
response = httpx.post("http://localhost:8000/api/v1/auth/register", json={
    "username": "testuser",
    "password": "testpass123",
    "email": "test@example.com"
})

# ç™»å½•è·å–token
response = httpx.post("http://localhost:8000/api/v1/auth/token", json={
    "username": "testuser",
    "password": "testpass123"
})
token = response.json()["access_token"]
headers = {"Authorization": f"Bearer {token}"}
```

### å¯¹è¯

```python
# æ™®é€šå¯¹è¯
response = httpx.post(
    "http://localhost:8000/api/v1/chat/completions",
    headers=headers,
    json={
        "messages": [
            {"role": "user", "content": "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹è‡ªå·±"}
        ],
        "model": "gpt-3.5-turbo",
        "temperature": 0.7
    }
)
print(response.json()["content"])
```

### RAG æŸ¥è¯¢

```python
# ä¸Šä¼ æ–‡æ¡£
response = httpx.post(
    "http://localhost:8000/api/v1/rag/documents",
    headers=headers,
    json={
        "documents": [
            {"content": "AI Agentæ˜¯ä¸€ç§æ™ºèƒ½ä»£ç†ç³»ç»Ÿ...", "metadata": {"source": "doc1"}},
            {"content": "RAGæ˜¯æ£€ç´¢å¢å¼ºç”ŸæˆæŠ€æœ¯...", "metadata": {"source": "doc2"}}
        ],
        "collection_name": "my_docs"
    }
)

# RAGæŸ¥è¯¢
response = httpx.post(
    "http://localhost:8000/api/v1/rag/query",
    headers=headers,
    json={
        "question": "ä»€ä¹ˆæ˜¯RAGï¼Ÿ",
        "collection_name": "my_docs",
        "top_k": 3
    }
)
print(response.json()["answer"])
```

### WebSocket æµå¼å¯¹è¯

```python
import asyncio
import websockets
import json

async def chat_stream():
    uri = f"ws://localhost:8000/ws/chat?token={token}&session_id=session1"
    
    async with websockets.connect(uri) as ws:
        # å‘é€æ¶ˆæ¯
        await ws.send(json.dumps({
            "action": "chat",
            "messages": [{"role": "user", "content": "å†™ä¸€é¦–å…³äºAIçš„è¯—"}],
            "model": "gpt-3.5-turbo"
        }))
        
        # æ¥æ”¶æµå¼å“åº”
        while True:
            response = await ws.recv()
            data = json.loads(response)
            if data["type"] == "chunk":
                print(data["content"], end="", flush=True)
            elif data["type"] == "end":
                break

asyncio.run(chat_stream())
```

### æ¨¡å‹å¾®è°ƒ

```python
# ä¸Šä¼ æ•°æ®é›†
response = httpx.post(
    "http://localhost:8000/api/v1/finetune/datasets",
    headers=headers,
    json={
        "name": "my_dataset",
        "format": "alpaca",
        "examples": [
            {"instruction": "ç¿»è¯‘æˆè‹±æ–‡", "input": "ä½ å¥½", "output": "Hello"},
            {"instruction": "ç¿»è¯‘æˆè‹±æ–‡", "input": "è°¢è°¢", "output": "Thank you"}
        ]
    }
)

# å¼€å§‹è®­ç»ƒ
response = httpx.post(
    "http://localhost:8000/api/v1/finetune/train",
    headers=headers,
    json={
        "dataset_name": "my_dataset",
        "config": {
            "model_name_or_path": "meta-llama/Llama-2-7b-hf",
            "output_name": "my_finetuned_model",
            "use_lora": True,
            "num_train_epochs": 3
        }
    }
)
job_id = response.json()["job_id"]

# æŸ¥è¯¢è®­ç»ƒçŠ¶æ€
response = httpx.get(
    f"http://localhost:8000/api/v1/finetune/train/{job_id}",
    headers=headers
)
print(response.json()["status"])
```

## ğŸ”§ æ‰©å±•å¼€å‘

### æ·»åŠ æ–°çš„LLMæä¾›å•†

```python
from core.llm.base import BaseLLM, Message, LLMResponse
from core.llm.factory import LLMFactory

class MyCustomLLM(BaseLLM):
    async def generate(self, messages: List[Message], **kwargs) -> LLMResponse:
        # å®ç°ç”Ÿæˆé€»è¾‘
        pass
    
    async def stream_generate(self, messages: List[Message], **kwargs):
        # å®ç°æµå¼ç”Ÿæˆ
        pass
    
    def get_provider_name(self) -> str:
        return "my_provider"

# æ³¨å†Œåˆ°å·¥å‚
LLMFactory.register_provider("my_provider", MyCustomLLM)
```

### æ·»åŠ è‡ªå®šä¹‰æç¤ºè¯æ¨¡æ¿

```python
from core.prompt.manager import PromptManager, PromptTemplate

manager = PromptManager()
manager.register(PromptTemplate(
    name="my_template",
    template="æ ¹æ®ä»¥ä¸‹ä¿¡æ¯å›ç­”: {context}\né—®é¢˜: {question}",
    variables=["context", "question"],
    category="custom"
))
```

### æ·»åŠ è‡ªå®šä¹‰è·¯ç”±è§„åˆ™

```python
from core.prompt.router import PromptRouter, RouteRule, RouterStrategy

router = PromptRouter(prompt_manager)
router.add_rule(RouteRule(
    name="custom_route",
    template_name="my_template",
    strategy=RouterStrategy.KEYWORD,
    keywords=["ç‰¹æ®Šå…³é”®è¯", "custom"],
    priority=20
))
```

## ğŸ“‹ API ç«¯ç‚¹

| ç«¯ç‚¹ | æ–¹æ³• | æè¿° |
|------|------|------|
| `/api/v1/auth/register` | POST | ç”¨æˆ·æ³¨å†Œ |
| `/api/v1/auth/token` | POST | è·å–JWTä»¤ç‰Œ |
| `/api/v1/chat/completions` | POST | å¯¹è¯è¡¥å…¨ |
| `/api/v1/chat/completions/stream` | POST | æµå¼å¯¹è¯ |
| `/api/v1/rag/documents` | POST | ä¸Šä¼ æ–‡æ¡£ |
| `/api/v1/rag/query` | POST | RAGæŸ¥è¯¢ |
| `/api/v1/memory/items` | POST | æ·»åŠ è®°å¿† |
| `/api/v1/memory/search` | POST | æœç´¢è®°å¿† |
| `/api/v1/finetune/datasets` | POST | ä¸Šä¼ æ•°æ®é›† |
| `/api/v1/finetune/train` | POST | å¼€å§‹è®­ç»ƒ |
| `/ws/chat` | WebSocket | æµå¼å¯¹è¯ |
| `/ws/rag` | WebSocket | æµå¼RAG |

## âš™ï¸ ç¯å¢ƒå˜é‡

| å˜é‡ | æè¿° | é»˜è®¤å€¼ |
|------|------|--------|
| `OPENAI_API_KEY` | OpenAI APIå¯†é’¥ | - |
| `DASHSCOPE_API_KEY` | é€šä¹‰åƒé—®APIå¯†é’¥ | - |
| `MILVUS_HOST` | Milvusåœ°å€ | localhost |
| `MILVUS_PORT` | Milvusç«¯å£ | 19530 |
| `JWT_SECRET_KEY` | JWTå¯†é’¥ | - |
| `EMBEDDING_MODEL` | åµŒå…¥æ¨¡å‹ | BAAI/bge-base-zh-v1.5 |
| `DEFAULT_LLM_PROVIDER` | é»˜è®¤LLMæä¾›å•† | openai |

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

- **Webæ¡†æ¶**: FastAPI
- **LLMæ¡†æ¶**: LangChain 1.x (LCEL)
- **å‘é‡æ•°æ®åº“**: Milvus
- **åµŒå…¥æ¨¡å‹**: SentenceTransformers
- **å¾®è°ƒ**: HuggingFace Transformers + PEFT
- **è®¤è¯**: JWT (python-jose)

## ğŸ“„ License

MIT License
