# ðŸ“š AI Agent Framework è¯¦ç»†å¼€å‘æ–‡æ¡£

æœ¬æ–‡æ¡£è¯¦ç»†ä»‹ç» AI Agent Framework çš„æž¶æž„è®¾è®¡ã€æ¨¡å—å®žçŽ°å’Œæ‰©å±•å¼€å‘æŒ‡å—ã€‚

---

## ðŸ“‹ ç›®å½•

1. [æž¶æž„æ¦‚è§ˆ](#æž¶æž„æ¦‚è§ˆ)
2. [æ ¸å¿ƒæ¨¡å—è¯¦è§£](#æ ¸å¿ƒæ¨¡å—è¯¦è§£)
3. [APIæŽ¥å£è§„èŒƒ](#apiæŽ¥å£è§„èŒƒ)
4. [æ‰©å±•å¼€å‘æŒ‡å—](#æ‰©å±•å¼€å‘æŒ‡å—)
5. [é…ç½®è¯´æ˜Ž](#é…ç½®è¯´æ˜Ž)
6. [éƒ¨ç½²æŒ‡å—](#éƒ¨ç½²æŒ‡å—)

---

## æž¶æž„æ¦‚è§ˆ

### ç³»ç»Ÿæž¶æž„å›¾

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Client Layer                              â”‚
â”‚         (Web App / Mobile App / CLI / Third-party)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                    HTTP/WebSocket Requests
                                â”‚
                                â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      FastAPI Application                         â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”           â”‚
â”‚  â”‚   Auth   â”‚ â”‚   Chat   â”‚ â”‚   RAG    â”‚ â”‚ Finetune â”‚           â”‚
â”‚  â”‚  Routes  â”‚ â”‚  Routes  â”‚ â”‚  Routes  â”‚ â”‚  Routes  â”‚           â”‚
â”‚  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜           â”‚
â”‚       â”‚            â”‚            â”‚            â”‚                   â”‚
â”‚       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                   â”‚
â”‚                          â”‚                                       â”‚
â”‚              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                          â”‚
â”‚              â”‚   Dependency Injection â”‚                          â”‚
â”‚              â”‚       (deps.py)        â”‚                          â”‚
â”‚              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       Core Modules                               â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚     LLM     â”‚  â”‚     RAG     â”‚  â”‚   Memory    â”‚             â”‚
â”‚  â”‚   Module    â”‚  â”‚   Module    â”‚  â”‚   Module    â”‚             â”‚
â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚             â”‚
â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚             â”‚
â”‚  â”‚ â”‚ OpenAI  â”‚ â”‚  â”‚ â”‚Embeddingâ”‚ â”‚  â”‚ â”‚ShortTermâ”‚ â”‚             â”‚
â”‚  â”‚ â”‚  Qwen   â”‚ â”‚  â”‚ â”‚Retrieverâ”‚ â”‚  â”‚ â”‚LongTerm â”‚ â”‚             â”‚
â”‚  â”‚ â”‚ LLaMA   â”‚ â”‚  â”‚ â”‚  Chain  â”‚ â”‚  â”‚ â”‚ Manager â”‚ â”‚             â”‚
â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚         â”‚                â”‚                â”‚                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚                                                â”‚             â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚             â”‚
â”‚  â”‚  â”‚   Prompt    â”‚  â”‚  Finetune   â”‚             â”‚             â”‚
â”‚  â”‚  â”‚   Module    â”‚  â”‚   Module    â”‚             â”‚             â”‚
â”‚  â”‚  â”‚             â”‚  â”‚             â”‚             â”‚             â”‚
â”‚  â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚             â”‚             â”‚
â”‚  â”‚  â”‚ â”‚ Manager â”‚ â”‚  â”‚ â”‚Processorâ”‚ â”‚             â”‚             â”‚
â”‚  â”‚  â”‚ â”‚ Router  â”‚ â”‚  â”‚ â”‚ Trainer â”‚ â”‚             â”‚             â”‚
â”‚  â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚  â”‚ â”‚  LoRA   â”‚ â”‚             â”‚             â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚             â”‚             â”‚
â”‚  â”‚                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    External Services                             â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”‚
â”‚  â”‚   OpenAI    â”‚  â”‚   Milvus    â”‚  â”‚  HuggingFaceâ”‚             â”‚
â”‚  â”‚    API      â”‚  â”‚   Vector    â”‚  â”‚    Models   â”‚             â”‚
â”‚  â”‚             â”‚  â”‚   Database  â”‚  â”‚             â”‚             â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â”‚
â”‚                                                                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
â”‚  â”‚  DashScope  â”‚  â”‚   Local     â”‚                               â”‚
â”‚  â”‚  (Qwen)     â”‚  â”‚   LLaMA     â”‚                               â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### è®¾è®¡åŽŸåˆ™

| åŽŸåˆ™ | è¯´æ˜Ž |
|------|------|
| **æ¨¡å—åŒ–** | å„æ¨¡å—ç‹¬ç«‹ï¼Œé€šè¿‡æŽ¥å£äº¤äº’ï¼Œå¯ç‹¬ç«‹æ›¿æ¢ |
| **å·¥åŽ‚æ¨¡å¼** | LLMé€šè¿‡å·¥åŽ‚ç»Ÿä¸€åˆ›å»ºï¼Œæ”¯æŒåŠ¨æ€åˆ‡æ¢ |
| **ä¾èµ–æ³¨å…¥** | FastAPI Dependsç®¡ç†ç”Ÿå‘½å‘¨æœŸ |
| **å¼‚æ­¥ä¼˜å…ˆ** | å…¨é“¾è·¯async/awaitï¼Œé«˜å¹¶å‘æ”¯æŒ |
| **é…ç½®åˆ†ç¦»** | æ•æ„Ÿä¿¡æ¯é€šè¿‡çŽ¯å¢ƒå˜é‡ç®¡ç† |

---

## æ ¸å¿ƒæ¨¡å—è¯¦è§£

### 1. LLM æ¨¡å— (`core/llm/`)

#### 1.1 æž¶æž„è®¾è®¡

```
core/llm/
â”œâ”€â”€ __init__.py        # æ¨¡å—å¯¼å‡º
â”œâ”€â”€ base.py            # æŠ½è±¡åŸºç±» BaseLLM
â”œâ”€â”€ openai_llm.py      # OpenAI ç›´æŽ¥å®žçŽ°
â”œâ”€â”€ qwen_llm.py        # é€šä¹‰åƒé—®å®žçŽ°
â”œâ”€â”€ llama_llm.py       # LLaMA å®žçŽ°
â”œâ”€â”€ langchain_llm.py   # LangChain 1.x åŒ…è£…å™¨ (æŽ¨è)
â””â”€â”€ factory.py         # LLM å·¥åŽ‚
```

#### 1.2 BaseLLM æŠ½è±¡ç±»

```python
from abc import ABC, abstractmethod
from typing import AsyncGenerator, List

class BaseLLM(ABC):
    """æ‰€æœ‰LLMå®žçŽ°çš„åŸºç±»"""
    
    def __init__(self, model_name: str, temperature: float = 0.7, max_tokens: int = 2048):
        self.model_name = model_name
        self.temperature = temperature
        self.max_tokens = max_tokens
    
    @abstractmethod
    async def generate(self, messages: List[Message], **kwargs) -> LLMResponse:
        """ç”Ÿæˆå“åº”ï¼ˆå¿…é¡»å®žçŽ°ï¼‰"""
        pass
    
    @abstractmethod
    async def stream_generate(self, messages: List[Message], **kwargs) -> AsyncGenerator[str, None]:
        """æµå¼ç”Ÿæˆï¼ˆå¿…é¡»å®žçŽ°ï¼‰"""
        pass
    
    @abstractmethod
    def get_provider_name(self) -> str:
        """è¿”å›žæä¾›å•†åç§°"""
        pass
```

#### 1.3 LangChain 1.x åŒ…è£…å™¨ï¼ˆæŽ¨èï¼‰

```python
from core.llm import LangChainLLM

# ä½¿ç”¨ LangChain 1.x API
llm = LangChainLLM(
    model_name="gpt-4",
    temperature=0.7,
    max_tokens=2048
)

# å¼‚æ­¥ç”Ÿæˆ (ä½¿ç”¨ ainvoke)
response = await llm.generate(messages)

# æµå¼è¾“å‡º (ä½¿ç”¨ astream)
async for chunk in llm.stream_generate(messages):
    print(chunk, end="")
```

#### 1.4 LLM å·¥åŽ‚æ¨¡å¼

```python
from core.llm.factory import LLMFactory

# åˆ›å»º LLM å®žä¾‹
llm = LLMFactory.create(
    provider="openai",      # æä¾›å•†
    model_name="gpt-4",     # æ¨¡åž‹å
    temperature=0.7,        # æ¸©åº¦
    max_tokens=2048         # æœ€å¤§token
)

# é€šè¿‡æ¨¡åž‹åè‡ªåŠ¨æŽ¨æ–­æä¾›å•†
llm = LLMFactory.create(model_name="qwen-turbo")  # è‡ªåŠ¨ä½¿ç”¨qwenæä¾›å•†

# æ³¨å†Œæ–°çš„æä¾›å•†
LLMFactory.register_provider("my_provider", MyCustomLLM)
```

#### 1.4 æ·»åŠ æ–° LLM æä¾›å•†

```python
# my_custom_llm.py
from core.llm.base import BaseLLM, Message, LLMResponse

class MyCustomLLM(BaseLLM):
    """è‡ªå®šä¹‰LLMå®žçŽ°"""
    
    def __init__(self, model_name: str, api_key: str = None, **kwargs):
        super().__init__(model_name, **kwargs)
        self.api_key = api_key or os.getenv("MY_API_KEY")
        self.client = MyAPIClient(api_key=self.api_key)
    
    async def generate(self, messages: List[Message], **kwargs) -> LLMResponse:
        response = await self.client.chat(
            messages=[{"role": m.role, "content": m.content} for m in messages],
            model=self.model_name,
            temperature=kwargs.get("temperature", self.temperature),
        )
        return LLMResponse(
            content=response.text,
            model=self.model_name,
            usage=response.usage
        )
    
    async def stream_generate(self, messages: List[Message], **kwargs):
        async for chunk in self.client.chat_stream(messages):
            yield chunk.text
    
    def get_provider_name(self) -> str:
        return "my_provider"

# æ³¨å†Œ
from core.llm.factory import LLMFactory
LLMFactory.register_provider("my_provider", MyCustomLLM)
LLMFactory.register_model("my-model-v1", "my_provider")
```

---

### 2. å‘é‡æ•°æ®åº“æ¨¡å— (`core/vector_store/`)

#### 2.1 æž¶æž„è®¾è®¡

```
core/vector_store/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ base.py           # æŠ½è±¡åŸºç±»
â””â”€â”€ milvus_store.py   # Milvus å®žçŽ°
```

#### 2.2 BaseVectorStore æŽ¥å£

```python
class BaseVectorStore(ABC):
    """å‘é‡å­˜å‚¨æŠ½è±¡åŸºç±»"""
    
    @abstractmethod
    async def create_collection(self, collection_name: str, dimension: int, **kwargs) -> bool:
        """åˆ›å»ºé›†åˆ"""
        pass
    
    @abstractmethod
    async def insert(self, collection_name: str, documents: List[Document]) -> List[str]:
        """æ’å…¥æ–‡æ¡£"""
        pass
    
    @abstractmethod
    async def search(self, collection_name: str, query_vector: List[float], 
                     top_k: int = 5, filters: dict = None) -> List[SearchResult]:
        """å‘é‡æœç´¢"""
        pass
    
    @abstractmethod
    async def delete(self, collection_name: str, ids: List[str]) -> bool:
        """åˆ é™¤æ–‡æ¡£"""
        pass
```

#### 2.3 Milvus é…ç½®

```python
# .env é…ç½®
MILVUS_HOST=localhost
MILVUS_PORT=19530
MILVUS_USER=
MILVUS_PASSWORD=
MILVUS_DB_NAME=ai_agent

# Docker å¯åŠ¨
docker-compose up -d etcd minio milvus
```

#### 2.4 é›†åˆç´¢å¼•é…ç½®

```python
from core.vector_store.milvus_store import MilvusVectorStore

store = MilvusVectorStore()

# åˆ›å»ºé›†åˆï¼ˆè‡ªå®šä¹‰ç´¢å¼•ï¼‰
await store.create_collection(
    collection_name="my_docs",
    dimension=768,              # å‘é‡ç»´åº¦
    index_type="IVF_FLAT",      # ç´¢å¼•ç±»åž‹: IVF_FLAT, IVF_SQ8, HNSW
    metric_type="COSINE",       # è·ç¦»åº¦é‡: COSINE, L2, IP
    nlist=1024                  # IVFå‚æ•°
)
```

---

### 3. RAG æ¨¡å— (`core/rag/`)

#### 3.1 æž¶æž„è®¾è®¡

```
core/rag/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ embeddings.py    # å‘é‡åµŒå…¥æ¨¡åž‹
â”œâ”€â”€ retriever.py     # æ–‡æ¡£æ£€ç´¢å™¨
â””â”€â”€ chain.py         # RAG é“¾
```

#### 3.2 Embedding æ¨¡åž‹

```python
from core.rag.embeddings import EmbeddingModel

# åˆå§‹åŒ–ï¼ˆé»˜è®¤ä½¿ç”¨ bge-base-zh-v1.5ï¼‰
embedding = EmbeddingModel(
    model_name="BAAI/bge-base-zh-v1.5",  # ä¸­æ–‡åµŒå…¥æ¨¡åž‹
    device="cpu"                          # æˆ– "cuda"
)

# åµŒå…¥æ–‡æœ¬
vectors = embedding.embed(["æ–‡æœ¬1", "æ–‡æœ¬2"])

# åµŒå…¥æŸ¥è¯¢ï¼ˆä¼šåŠ queryå‰ç¼€ä¼˜åŒ–ï¼‰
query_vec = embedding.embed_query("æŸ¥è¯¢é—®é¢˜")

# èŽ·å–ç»´åº¦
dim = embedding.dimension  # 768
```

#### 3.3 Retriever æ£€ç´¢å™¨

```python
from core.rag.retriever import Retriever

retriever = Retriever(
    vector_store=vector_store,
    embedding_model=embedding_model,
    collection_name="my_docs",
    top_k=5,
    score_threshold=0.5  # ç›¸ä¼¼åº¦é˜ˆå€¼
)

# æ·»åŠ æ–‡æ¡£
ids = await retriever.add_documents([
    {"content": "æ–‡æ¡£å†…å®¹1", "metadata": {"source": "file1.txt"}},
    {"content": "æ–‡æ¡£å†…å®¹2", "metadata": {"source": "file2.txt"}},
])

# æ£€ç´¢
results = await retriever.retrieve("æŸ¥è¯¢é—®é¢˜", top_k=3)
for r in results:
    print(f"Score: {r.score}, Content: {r.content}")
```

#### 3.4 RAG Chain

```python
from core.rag.chain import RAGChain

rag = RAGChain(
    llm=llm,
    retriever=retriever,
    template="""åŸºäºŽä»¥ä¸‹ä¸Šä¸‹æ–‡å›žç­”é—®é¢˜ã€‚

ä¸Šä¸‹æ–‡:
{context}

é—®é¢˜: {question}

å›žç­”:""",
    include_sources=True,     # è¿”å›žæ¥æº
    max_context_length=4000   # ä¸Šä¸‹æ–‡æœ€å¤§é•¿åº¦
)

# æŸ¥è¯¢
result = await rag.query(
    question="ä»€ä¹ˆæ˜¯RAGï¼Ÿ",
    top_k=5,
    filters={"source": "official_docs"}  # å¯é€‰è¿‡æ»¤
)

print(result["answer"])
print(result["sources"])  # æ¥æºæ–‡æ¡£

# æµå¼æŸ¥è¯¢
async for chunk in rag.stream_query("ä»€ä¹ˆæ˜¯RAGï¼Ÿ"):
    print(chunk, end="")
```

---

### 4. æç¤ºè¯æ¨¡å— (`core/prompt/`)

#### 4.1 æž¶æž„è®¾è®¡

```
core/prompt/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ manager.py       # æ¨¡æ¿ç®¡ç†å™¨
â”œâ”€â”€ router.py        # è·¯ç”±å™¨
â””â”€â”€ templates/       # æ¨¡æ¿æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰
```

#### 4.2 PromptManager æ¨¡æ¿ç®¡ç†

```python
from core.prompt.manager import PromptManager, PromptTemplate

manager = PromptManager()

# æ³¨å†Œæ¨¡æ¿
manager.register(PromptTemplate(
    name="customer_service",
    template="""ä½ æ˜¯{company}çš„å®¢æœåŠ©æ‰‹ã€‚

ç”¨æˆ·é—®é¢˜: {question}

è¯·ç”¨ä¸“ä¸šã€å‹å¥½çš„è¯­æ°”å›žç­”ã€‚""",
    description="å®¢æœåœºæ™¯æç¤ºè¯",
    variables=["company", "question"],
    category="service"
))

# èŽ·å–å¹¶æ ¼å¼åŒ–
template = manager.get("customer_service")
prompt = template.format(company="XXå…¬å¸", question="å¦‚ä½•é€€æ¬¾ï¼Ÿ")

# åˆ—å‡ºæ‰€æœ‰æ¨¡æ¿
templates = manager.list_templates(category="service")

# ä¿å­˜/åŠ è½½
manager.save_to_file("prompts.json")
manager.load_from_file("prompts.json")
```

#### 4.3 PromptRouter æ™ºèƒ½è·¯ç”±

```python
from core.prompt.router import PromptRouter, RouteRule, RouterStrategy

router = PromptRouter(prompt_manager=manager)

# æ·»åŠ è·¯ç”±è§„åˆ™
router.add_rule(RouteRule(
    name="translate_route",
    template_name="translate",
    strategy=RouterStrategy.KEYWORD,
    keywords=["ç¿»è¯‘", "translate", "è½¬æ¢æˆ"],
    priority=10
))

router.add_rule(RouteRule(
    name="code_route",
    template_name="code_review",
    strategy=RouterStrategy.REGEX,
    pattern=r"(å®¡æŸ¥|review|æ£€æŸ¥).*ä»£ç ",
    priority=10
))

# è‡ªåŠ¨è·¯ç”±
template = await router.route("å¸®æˆ‘ç¿»è¯‘è¿™æ®µè¯")
# è¿”å›ž translate æ¨¡æ¿

# LLMæ™ºèƒ½è·¯ç”±
router.llm = llm
router.add_rule(RouteRule(
    name="smart_route",
    template_name="general",
    strategy=RouterStrategy.LLM,
    priority=1  # æœ€ä½Žä¼˜å…ˆçº§ï¼Œå…œåº•
))
```

---

### 5. è®°å¿†æ¨¡å— (`core/memory/`)

#### 5.1 æž¶æž„è®¾è®¡

```
core/memory/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ base.py          # æŠ½è±¡åŸºç±»
â”œâ”€â”€ short_term.py    # çŸ­æœŸè®°å¿†ï¼ˆæ»‘åŠ¨çª—å£ï¼‰
â”œâ”€â”€ long_term.py     # é•¿æœŸè®°å¿†ï¼ˆå‘é‡å­˜å‚¨ï¼‰
â””â”€â”€ manager.py       # ç»Ÿä¸€ç®¡ç†å™¨
```

#### 5.2 çŸ­æœŸè®°å¿† (ShortTermMemory)

```python
from core.memory.short_term import ShortTermMemory

memory = ShortTermMemory(
    max_size=10,           # æœ€å¤šä¿ç•™10æ¡
    session_id="session1"
)

# æ·»åŠ æ¶ˆæ¯
await memory.add_user_message("ä½ å¥½")
await memory.add_assistant_message("ä½ å¥½ï¼æœ‰ä»€ä¹ˆå¯ä»¥å¸®ä½ çš„ï¼Ÿ")

# èŽ·å–æœ€è¿‘æ¶ˆæ¯
recent = await memory.get_recent(5)

# è½¬æ¢ä¸ºLLMæ¶ˆæ¯æ ¼å¼
messages = memory.to_messages()

# èŽ·å–ä¸Šä¸‹æ–‡çª—å£ï¼ˆtokené™åˆ¶ï¼‰
context = await memory.get_context_window(max_tokens=4000)
```

#### 5.3 é•¿æœŸè®°å¿† (LongTermMemory)

```python
from core.memory.long_term import LongTermMemory

memory = LongTermMemory(
    vector_store=vector_store,
    embedding_model=embedding_model,
    collection_name="user_memory",
    user_id="user123"
)

# æ·»åŠ è®°å¿†
await memory.add(MemoryItem(
    content="ç”¨æˆ·å–œæ¬¢Pythonç¼–ç¨‹",
    role="system",
    importance=0.8,
    metadata={"type": "preference"}
))

# è¯­ä¹‰æœç´¢
results = await memory.search("ç¼–ç¨‹è¯­è¨€åå¥½", limit=5)

# èŽ·å–é‡è¦è®°å¿†
important = await memory.get_by_importance(min_importance=0.7)
```

#### 5.4 MemoryManager ç»Ÿä¸€ç®¡ç†

```python
from core.memory.manager import MemoryManager

manager = MemoryManager(
    short_term=short_term_memory,
    long_term=long_term_memory,
    llm=llm,                    # ç”¨äºŽæ‘˜è¦
    auto_archive=True,          # è‡ªåŠ¨å½’æ¡£é‡è¦è®°å¿†
    archive_threshold=0.6       # å½’æ¡£é˜ˆå€¼
)

# æ·»åŠ å¯¹è¯
await manager.add_conversation_turn(
    user_message="æˆ‘æƒ³å­¦ä¹ AI",
    assistant_message="å¤ªå¥½äº†ï¼ä½ å¯¹å“ªä¸ªæ–¹å‘æ„Ÿå…´è¶£ï¼Ÿ"
)

# èŽ·å–å¯¹è¯åŽ†å²
history = await manager.get_conversation_history(max_turns=5)

# æœç´¢æ‰€æœ‰è®°å¿†
results = await manager.search_all("AIå­¦ä¹ ", include_long_term=True)

# æ‘˜è¦å¹¶å½’æ¡£
summary_id = await manager.summarize_and_archive(max_items=20)
```

---

### 6. å¾®è°ƒæ¨¡å— (`core/finetune/`)

#### 6.1 æž¶æž„è®¾è®¡

```
core/finetune/
â”œâ”€â”€ __init__.py
â”œâ”€â”€ data_processor.py    # æ•°æ®å¤„ç†
â”œâ”€â”€ trainer.py           # è®­ç»ƒå™¨
â””â”€â”€ lora_adapter.py      # LoRAé€‚é…å™¨
```

#### 6.2 æ•°æ®å¤„ç† (DataProcessor)

```python
from core.finetune.data_processor import DataProcessor, TrainingExample

processor = DataProcessor(format="alpaca")

# åˆ›å»ºè®­ç»ƒæ ·æœ¬
examples = [
    TrainingExample(
        instruction="ç¿»è¯‘æˆè‹±æ–‡",
        input="ä½ å¥½ä¸–ç•Œ",
        output="Hello World"
    ),
    TrainingExample(
        instruction="æ€»ç»“ä»¥ä¸‹æ–‡æœ¬",
        input="å¾ˆé•¿çš„æ–‡æœ¬...",
        output="ç®€çŸ­æ‘˜è¦"
    )
]

# éªŒè¯æ•°æ®
report = processor.validate_examples(examples)
print(f"æœ‰æ•ˆ: {report['valid']}, æ— æ•ˆ: {report['invalid']}")

# è½¬æ¢æ ¼å¼
alpaca_data = processor.convert(examples, target_format="alpaca")
openai_data = processor.convert(examples, target_format="openai")
sharegpt_data = processor.convert(examples, target_format="sharegpt")

# ä¿å­˜æ•°æ®
processor.save_jsonl(alpaca_data, "train.jsonl")

# åˆ†å‰²æ•°æ®é›†
train, val = processor.split_dataset(examples, train_ratio=0.9)

# è½¬HuggingFace Dataset
hf_dataset = processor.to_hf_dataset(examples, tokenizer=tokenizer)
```

#### 6.3 LoRA å¾®è°ƒ

```python
from core.finetune.lora_adapter import LoRAAdapter, LoRAConfig

# é…ç½®
config = LoRAConfig(
    r=8,                    # LoRA rank
    lora_alpha=16,          # Alpha
    lora_dropout=0.1,
    target_modules=["q_proj", "v_proj", "k_proj", "o_proj"],
    use_4bit=True,          # 4bité‡åŒ–
)

# åˆ›å»ºé€‚é…å™¨
adapter = LoRAAdapter(
    base_model_path="meta-llama/Llama-2-7b-hf",
    config=config
)

# åŠ è½½æ¨¡åž‹å¹¶åº”ç”¨LoRA
adapter.load_base_model()
adapter.apply_lora()

# ä¿å­˜é€‚é…å™¨
adapter.save_adapter("./my_lora_adapter")

# åŠ è½½é€‚é…å™¨
adapter.load_adapter("./my_lora_adapter")

# åˆå¹¶æƒé‡
adapter.merge_and_save("./merged_model")

# æŽ¨ç†
response = adapter.generate("ä½ å¥½", max_new_tokens=100)
```

#### 6.4 å…¨é‡å¾®è°ƒ (FineTuneTrainer)

```python
from core.finetune.trainer import FineTuneTrainer, TrainingConfig

config = TrainingConfig(
    model_name_or_path="meta-llama/Llama-2-7b-hf",
    output_dir="./finetuned_model",
    num_train_epochs=3,
    learning_rate=2e-5,
    per_device_train_batch_size=4,
    gradient_accumulation_steps=4,
    max_seq_length=2048,
    use_lora=False,          # å…¨é‡å¾®è°ƒ
    fp16=True,               # æ··åˆç²¾åº¦
)

trainer = FineTuneTrainer(config)
trainer.load_model()

# è®­ç»ƒ
result = trainer.train(train_dataset, eval_dataset)
print(f"Loss: {result['train_loss']}")

# ä¿å­˜
trainer.save_model()

# æŽ¨ç†
response = trainer.generate("æµ‹è¯•æç¤º")
```

---

## APIæŽ¥å£è§„èŒƒ

### è®¤è¯æµç¨‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Client  â”‚     â”‚   API    â”‚     â”‚   Auth   â”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
     â”‚                â”‚                â”‚
     â”‚ POST /register â”‚                â”‚
     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                â”‚
     â”‚                â”‚ create user    â”‚
     â”‚                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
     â”‚                â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                â”‚
     â”‚                â”‚                â”‚
     â”‚ POST /token    â”‚                â”‚
     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                â”‚
     â”‚                â”‚ verify & sign  â”‚
     â”‚                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
     â”‚                â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                â”‚
     â”‚   JWT Token    â”‚                â”‚
     â”‚                â”‚                â”‚
     â”‚ GET /protected â”‚                â”‚
     â”‚ Authorization: â”‚                â”‚
     â”‚ Bearer <token> â”‚                â”‚
     â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚                â”‚
     â”‚                â”‚ verify token   â”‚
     â”‚                â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€>â”‚
     â”‚                â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚
     â”‚<â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”‚                â”‚
     â”‚   Response     â”‚                â”‚
```

### API ç«¯ç‚¹è¯¦æƒ…

#### è®¤è¯ (`/api/v1/auth`)

| ç«¯ç‚¹ | æ–¹æ³• | æè¿° | è®¤è¯ |
|------|------|------|------|
| `/register` | POST | æ³¨å†Œæ–°ç”¨æˆ· | å¦ |
| `/token` | POST | èŽ·å–JWTä»¤ç‰Œ | å¦ |
| `/login` | POST | è¡¨å•ç™»å½• | å¦ |
| `/me` | GET | èŽ·å–å½“å‰ç”¨æˆ· | æ˜¯ |
| `/refresh` | POST | åˆ·æ–°ä»¤ç‰Œ | æ˜¯ |

#### å¯¹è¯ (`/api/v1/chat`)

| ç«¯ç‚¹ | æ–¹æ³• | æè¿° | è®¤è¯ |
|------|------|------|------|
| `/completions` | POST | å¯¹è¯è¡¥å…¨ | æ˜¯ |
| `/completions/stream` | POST | æµå¼å¯¹è¯ | æ˜¯ |
| `/models` | GET | åˆ—å‡ºæ¨¡åž‹ | æ˜¯ |
| `/route` | POST | æç¤ºè¯è·¯ç”± | æ˜¯ |

#### RAG (`/api/v1/rag`)

| ç«¯ç‚¹ | æ–¹æ³• | æè¿° | è®¤è¯ |
|------|------|------|------|
| `/collections` | POST | åˆ›å»ºé›†åˆ | æ˜¯ |
| `/collections/{name}` | DELETE | åˆ é™¤é›†åˆ | æ˜¯ |
| `/documents` | POST | ä¸Šä¼ æ–‡æ¡£ | æ˜¯ |
| `/query` | POST | RAGæŸ¥è¯¢ | æ˜¯ |
| `/query/stream` | POST | æµå¼RAG | æ˜¯ |
| `/search` | GET | æ–‡æ¡£æœç´¢ | æ˜¯ |

#### è®°å¿† (`/api/v1/memory`)

| ç«¯ç‚¹ | æ–¹æ³• | æè¿° | è®¤è¯ |
|------|------|------|------|
| `/items` | POST | æ·»åŠ è®°å¿† | æ˜¯ |
| `/search` | POST | æœç´¢è®°å¿† | æ˜¯ |
| `/history` | POST | èŽ·å–åŽ†å² | æ˜¯ |
| `/stats/{session_id}` | GET | ç»Ÿè®¡ä¿¡æ¯ | æ˜¯ |
| `/clear` | POST | æ¸…é™¤è®°å¿† | æ˜¯ |
| `/archive/{session_id}` | POST | å½’æ¡£è®°å¿† | æ˜¯ |

#### å¾®è°ƒ (`/api/v1/finetune`)

| ç«¯ç‚¹ | æ–¹æ³• | æè¿° | è®¤è¯ |
|------|------|------|------|
| `/datasets` | POST | ä¸Šä¼ æ•°æ®é›† | æ˜¯ |
| `/datasets` | GET | åˆ—å‡ºæ•°æ®é›† | æ˜¯ |
| `/train` | POST | å¼€å§‹è®­ç»ƒ | æ˜¯ |
| `/train/{job_id}` | GET | è®­ç»ƒçŠ¶æ€ | æ˜¯ |
| `/models` | GET | åˆ—å‡ºæ¨¡åž‹ | æ˜¯ |

#### WebSocket

| ç«¯ç‚¹ | æè¿° |
|------|------|
| `/ws/chat?token=xxx&session_id=xxx` | æµå¼å¯¹è¯ |
| `/ws/rag?token=xxx&collection_name=xxx` | æµå¼RAG |

---

## æ‰©å±•å¼€å‘æŒ‡å—

### æ·»åŠ æ–°çš„å‘é‡æ•°æ®åº“

```python
# core/vector_store/pinecone_store.py
from core.vector_store.base import BaseVectorStore

class PineconeVectorStore(BaseVectorStore):
    def __init__(self, api_key: str, environment: str):
        import pinecone
        pinecone.init(api_key=api_key, environment=environment)
        self.index = None
    
    async def create_collection(self, collection_name: str, dimension: int, **kwargs):
        import pinecone
        if collection_name not in pinecone.list_indexes():
            pinecone.create_index(collection_name, dimension=dimension)
        self.index = pinecone.Index(collection_name)
        return True
    
    async def insert(self, collection_name: str, documents: List[Document]):
        vectors = [
            (doc.id, doc.embedding, {"content": doc.content, **doc.metadata})
            for doc in documents
        ]
        self.index.upsert(vectors)
        return [doc.id for doc in documents]
    
    async def search(self, collection_name: str, query_vector: List[float], 
                     top_k: int = 5, filters: dict = None):
        results = self.index.query(query_vector, top_k=top_k, include_metadata=True)
        return [
            SearchResult(id=r.id, content=r.metadata["content"], score=r.score)
            for r in results.matches
        ]
```

### æ·»åŠ æ–°çš„ API è·¯ç”±

```python
# app/api/routes/my_feature.py
from fastapi import APIRouter, Depends
from app.api.auth import get_current_user

router = APIRouter(prefix="/my-feature", tags=["MyFeature"])

@router.post("/action")
async def my_action(
    data: MyRequest,
    current_user = Depends(get_current_user)
):
    # å®žçŽ°é€»è¾‘
    return {"result": "success"}

# åœ¨ app/api/routes/__init__.py æ·»åŠ 
from app.api.routes.my_feature import router as my_feature_router

# åœ¨ app/main.py æ³¨å†Œ
app.include_router(my_feature_router, prefix=api_prefix)
```

---

## é…ç½®è¯´æ˜Ž

### çŽ¯å¢ƒå˜é‡å®Œæ•´åˆ—è¡¨

```bash
# === åº”ç”¨é…ç½® ===
APP_NAME=AI Agent Framework
APP_ENV=development          # development / production
DEBUG=true

# === JWTè®¤è¯ ===
JWT_SECRET_KEY=your-secret-key-must-change-in-production
JWT_ALGORITHM=HS256
JWT_ACCESS_TOKEN_EXPIRE_MINUTES=30

# === OpenAI ===
OPENAI_API_KEY=sk-xxx
OPENAI_API_BASE=https://api.openai.com/v1

# === é€šä¹‰åƒé—® ===
DASHSCOPE_API_KEY=sk-xxx

# === LLaMA ===
LLAMA_MODEL_PATH=/path/to/model
LLAMA_API_BASE=http://localhost:8080

# === Milvus ===
MILVUS_HOST=localhost
MILVUS_PORT=19530
MILVUS_USER=
MILVUS_PASSWORD=
MILVUS_DB_NAME=ai_agent

# === Embedding ===
EMBEDDING_MODEL=BAAI/bge-base-zh-v1.5
EMBEDDING_DEVICE=cpu          # cpu / cuda

# === é»˜è®¤LLM ===
DEFAULT_LLM_PROVIDER=openai
DEFAULT_MODEL_NAME=gpt-3.5-turbo
DEFAULT_TEMPERATURE=0.7
DEFAULT_MAX_TOKENS=2048

# === è®°å¿† ===
SHORT_TERM_MEMORY_SIZE=10
LONG_TERM_MEMORY_COLLECTION=long_term_memory

# === å¾®è°ƒ ===
FINETUNE_OUTPUT_DIR=./finetune_output
FINETUNE_LOGGING_DIR=./finetune_logs
```

---

## éƒ¨ç½²æŒ‡å—

### Docker éƒ¨ç½²

```bash
# æž„å»ºé•œåƒ
docker build -t ai-agent-framework .

# è¿è¡Œï¼ˆéœ€è¦å…ˆå¯åŠ¨Milvusï¼‰
docker run -d \
  --name ai-agent \
  -p 8000:8000 \
  --env-file .env \
  -v $(pwd)/finetune_output:/app/finetune_output \
  ai-agent-framework

# ä¸€é”®éƒ¨ç½²ï¼ˆåŒ…å«Milvusï¼‰
docker-compose up -d
```

### ç”Ÿäº§çŽ¯å¢ƒå»ºè®®

1. **å®‰å…¨é…ç½®**
   - ä¿®æ”¹ `JWT_SECRET_KEY` ä¸ºå¼ºéšæœºå­—ç¬¦ä¸²
   - é…ç½® CORS ç™½åå•
   - å¯ç”¨ HTTPS

2. **æ€§èƒ½ä¼˜åŒ–**
   - ä½¿ç”¨ Gunicorn å¤š worker
   - é…ç½®è¿žæŽ¥æ± 
   - å¯ç”¨ç¼“å­˜

3. **ç›‘æŽ§**
   - é›†æˆ Prometheus æŒ‡æ ‡
   - é…ç½®æ—¥å¿—æ”¶é›†
   - è®¾ç½®å‘Šè­¦

```bash
# ç”Ÿäº§å¯åŠ¨å‘½ä»¤
gunicorn app.main:app \
  --workers 4 \
  --worker-class uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8000 \
  --access-logfile - \
  --error-logfile -
```

---

## å‚è€ƒèµ„æ–™

- [FastAPI å®˜æ–¹æ–‡æ¡£](https://fastapi.tiangolo.com/)
- [LangChain 1.x æ–‡æ¡£](https://python.langchain.com/docs/)
- [Milvus æ–‡æ¡£](https://milvus.io/docs)
- [HuggingFace Transformers](https://huggingface.co/docs/transformers)
- [PEFT æ–‡æ¡£](https://huggingface.co/docs/peft)
